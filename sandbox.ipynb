{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_H_vu1yHWZ9"
   },
   "outputs": [],
   "source": [
    "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMaZefJf71ba"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning\n",
    "!pip install lightning-bolts\n",
    "!pip install tokenizers\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuTlEVQeH8VX"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/krasserm/perceiver-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znAFBf7FAE74"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "os.chdir('/content/perceiver-io')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout wip-tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceiver.adapter import ImageInputAdapter, ClassificationOutputAdapter\n",
    "from perceiver.model import PerceiverIO, PerceiverEncoder, PerceiverDecoder\n",
    "\n",
    "latent_shape = (32, 128)\n",
    "\n",
    "# Fourier-encode pixel positions and flatten along spatial dimensions\n",
    "input_adapter = ImageInputAdapter(image_shape=(28, 28, 1), num_frequency_bands=32)\n",
    "\n",
    "# Project generic Perceiver decoder output to specified number of classes\n",
    "output_adapter = ClassificationOutputAdapter(num_classes=10, num_output_channels=128)\n",
    "\n",
    "# Generic Perceiver encoder\n",
    "encoder = PerceiverEncoder(\n",
    "    input_adapter=input_adapter,\n",
    "    latent_shape=latent_shape,\n",
    "    num_layers=3,\n",
    "    num_cross_attention_heads=4,\n",
    "    num_self_attention_heads=4,\n",
    "    num_self_attention_layers_per_block=3,\n",
    "    dropout=0.0)\n",
    "\n",
    "# Generic Perceiver decoder\n",
    "decoder = PerceiverDecoder(\n",
    "    output_adapter=output_adapter,\n",
    "    latent_shape=latent_shape,\n",
    "    num_cross_attention_heads=1,\n",
    "    dropout=0.0)\n",
    "\n",
    "# MNIST classifier implemented as Perceiver IO model\n",
    "mnist_classifier = PerceiverIO(encoder, decoder)\n",
    "mnist_classifier = mnist_classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(mnist_classifier(torch.rand(2, 28, 28, 1).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TznzBht--zbm"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from data import IMDBDataModule\n",
    "from train.train_mlm import LitMLM, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ci_XYspCBM-y"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = IMDBDataModule.setup_parser(parser)\n",
    "parser = LitMLM.setup_parser(parser)\n",
    "\n",
    "group = parser.add_argument_group('main')\n",
    "group.add_argument('--experiment', default='mlm', help=' ')\n",
    "\n",
    "parser.set_defaults(\n",
    "    num_latents=64,\n",
    "    num_latent_channels=64,\n",
    "    num_encoder_layers=3,\n",
    "    dropout=0.0,\n",
    "    weight_decay=0.0,\n",
    "    learning_rate=3e-3,\n",
    "    max_seq_len=512,\n",
    "    max_steps=50000,\n",
    "    batch_size=64,\n",
    "    one_cycle_lr=True,\n",
    "    one_cycle_pct_start=0.1,\n",
    "    tpu_cores=[1],\n",
    "    limit_train_batches=5,\n",
    "    limit_val_batches=5,\n",
    "    log_every_n_steps=5,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    strategy='tpu_spawn_debug',\n",
    "    default_root_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCLvb9_oDXPW"
   },
   "outputs": [],
   "source": [
    "main(parser.parse_args([]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyP/eauNyDtdfCP+pGNCOqt3",
   "collapsed_sections": [],
   "name": "perceiver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
